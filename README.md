

# Pipeline de Dados para Cervejarias ğŸº

Este projeto implementa um pipeline completo de dados que coleta informaÃ§Ãµes de cervejarias da Open Brewery DB API, processa e armazena em um data lake seguindo a arquitetura bronze, prata, ouro, com interface grÃ¡fica para controle.

## ğŸ“‹ PrÃ©-requisitos

* Docker Desktop instalado
* Python 3.8+ (para execuÃ§Ã£o local)
* 4GB+ de memÃ³ria RAM disponÃ­vel
* ConexÃ£o com internet para acessar a API
* Git (para clonar o repositÃ³rio)

## ğŸ—ï¸ Estrutura do Projeto

teste_PSW_jpm/
â”œâ”€â”€ dados/
â”‚ â”œâ”€â”€ bronze/ # Dados brutos da API
â”‚ â”œâ”€â”€ prata/ # Dados processados
â”‚ â”œâ”€â”€ ouro/ # Dados agregados
â”‚ â”œâ”€â”€ resumo_prata.csv # Resumo estatÃ­stico
â”‚ â””â”€â”€ resumo_ouro.csv # Resumo analÃ­tico
â”œâ”€â”€ docker/
â”‚ â”œâ”€â”€ Dockerfile # ConfiguraÃ§Ã£o do container
â”‚ â””â”€â”€ requirements.txt # DependÃªncias do projeto
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ consumidor_api.py # Coleta de dados da API
â”‚ â”œâ”€â”€ transformacao.py # TransformaÃ§Ãµes de dados
â”‚ â”œâ”€â”€ verificacao_qualidade_dados.py # ValidaÃ§Ã£o de dados
â”‚ â””â”€â”€ monitoramento.py # Monitoramento do pipeline
â”œâ”€â”€ testes/
â”‚ â”œâ”€â”€ test_consumidor_api.py # Testes da API
â”‚ â”œâ”€â”€ test_transformacao.py # Testes de transformaÃ§Ã£o
â”‚ â”œâ”€â”€ test_verificacao_qualidade.py # Testes de qualidade
â”‚ â””â”€â”€ test_monitoramento.py # Testes de monitoramento
â”œâ”€â”€ dags/
â”‚ â””â”€â”€ cervejarias_pipeline.py # Pipeline Airflow
â”œâ”€â”€ executar_pipeline.py # Script principal
â”œâ”€â”€ interface_pipeline.py # Interface grÃ¡fica
â”œâ”€â”€ visualizar_dados.py # VisualizaÃ§Ã£o de resultados
â””â”€â”€ README.md

## ğŸš€ Como Executar

### OpÃ§Ã£o 1: Via Docker (Recomendado para produÃ§Ã£o)

1. **Construir a imagem Docker**:
```powershell
docker build -t pipeline-cervejarias -f docker/Dockerfile .

2. **Executar o pipeline completo** :

powershell

docker run -it --rm -v ${PWD}/dados:/dados pipeline-cervejarias python3 executar_pipeline.py

3. **Abrir a interface grÃ¡fica** :

powershell

python interface_pipeline.py

### OpÃ§Ã£o 2: ExecuÃ§Ã£o com Airflow (Para orquestraÃ§Ã£o)

1. **Iniciar os containers** :

powershell

docker-compose up -d

2. **Acessar a interface do Airflow** :
   Acesse `http://localhost:8080` no navegador (usuÃ¡rio: admin, senha: admin)
3. **Ativar o DAG** :
   Na interface do Airflow, ative o DAG `cervejarias_pipeline` que serÃ¡ executado diariamente

### OpÃ§Ã£o 3: ExecuÃ§Ã£o Local (Para desenvolvimento)

1. **Configurar ambiente virtual** :

powershell

python -m venv venv
.\venv\Scripts\activate
pip install -r docker/requirements.txt

2. **Executar o pipeline** :

powershell

python executar_pipeline.py

3. **Abrir a interface grÃ¡fica** :

powershell

python interface_pipeline.py


## ğŸ–¥ï¸ Interface GrÃ¡fica

A interface Tkinter fornece controle completo sobre o pipeline

Funcionalidades:

* ExecuÃ§Ã£o individual de cada etapa do pipeline
* VisualizaÃ§Ã£o em tempo real dos logs
* Controle de processos
* ExibiÃ§Ã£o de resultados

## ğŸ“Š VisualizaÃ§Ã£o de Dados

ApÃ³s executar o pipeline, vocÃª pode:

1. Ver os arquivos CSV gerados:
   * `dados/resumo_prata.csv` (dados processados)
   * `dados/resumo_ouro.csv` (dados agregados)
2. Visualizar os grÃ¡ficos gerados:
   * `dados/grafico_paises_prata.png`
   * `dados/grafico_paises_ouro.png`
3. Usar o visualizador integrado:

powershell

python visualizar_dados.py

## ğŸ§ª Testes

Execute todos os testes com:

powershell

python -m pytest testes/

Ou testes individuais:

powershell

python -m pytest testes/test_consumidor_api.py -v

## ğŸ“ PersonalizaÃ§Ã£o

Principais pontos de configuraÃ§Ã£o:

| Arquivo                            | PropÃ³sito                            |
| ---------------------------------- | ------------------------------------- |
| `executar_pipeline.py`           | ConfiguraÃ§Ã£o geral do pipeline      |
| `verificacao_qualidade_dados.py` | Regras de validaÃ§Ã£o de dados        |
| `transformacao.py`               | LÃ³gica de transformaÃ§Ã£o dos dados  |
| `monitoramento.py`               | ConfiguraÃ§Ã£o de alertas e mÃ©tricas |

## ğŸ“ˆ Fluxo de Dados

1. **Bronze** : Coleta bruta da API â†’ JSON
2. **Prata** : Limpeza e validaÃ§Ã£o â†’ Parquet
3. **Ouro** : AgregaÃ§Ã£o e anÃ¡lise â†’ CSV/Parquet
